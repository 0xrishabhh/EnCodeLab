#!/usr/bin/env python3
"""
Test script for the benchmark endpoint
"""

import requests
import json
import time

def test_benchmark():
    """Test the benchmark endpoint with different configurations"""
    
    base_url = "http://localhost:5000"
    
    # Test configurations
    test_configs = [
        {
            "name": "AES-CBC Small Data",
            "algorithm": "AES",
            "mode": "CBC",
            "testData": "Hello World! This is a test message.",
            "iterations": 5
        },
        {
            "name": "3DES-CBC Small Data",
            "algorithm": "3DES",
            "mode": "CBC",
            "testData": "Hello World! This is a test message.",
            "iterations": 5
        },
        {
            "name": "AES-ECB Large Data",
            "algorithm": "AES",
            "mode": "ECB",
            "testData": "A" * 1024,  # 1KB of data
            "iterations": 3
        }
    ]
    
    print("ğŸ§ª Starting Benchmark Endpoint Tests...")
    
    for config in test_configs:
        print(f"\nğŸ”¬ Testing: {config['name']}")
        
        try:
            # Make benchmark request
            response = requests.post(
                f"{base_url}/benchmark",
                json={
                    "algorithm": config["algorithm"],
                    "mode": config["mode"],
                    "testData": config["testData"],
                    "iterations": config["iterations"]
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("status") == "success":
                    benchmark_result = result["result"]
                    
                    print(f"   âœ… Success!")
                    print(f"   ğŸ“Š Algorithm: {benchmark_result['algorithm']}")
                    print(f"   ğŸ”§ Mode: {benchmark_result['mode']}")
                    print(f"   ğŸ“ Data Size: {benchmark_result['dataSize']} bytes")
                    print(f"   ğŸ”„ Iterations: {benchmark_result['iterations']}")
                    print(f"   â±ï¸  Encryption: {benchmark_result['encryption']['avgTimeMs']}ms avg")
                    print(f"   â±ï¸  Decryption: {benchmark_result['decryption']['avgTimeMs']}ms avg")
                    print(f"   ğŸš€ Encryption Throughput: {benchmark_result['encryption']['throughputMBps']} MB/s")
                    print(f"   ğŸš€ Decryption Throughput: {benchmark_result['decryption']['throughputMBps']} MB/s")
                    print(f"   ğŸ’¾ Memory Usage: {benchmark_result['memory']['avgUsageMB']} MB avg")
                    
                else:
                    print(f"   âŒ API Error: {result.get('error', 'Unknown error')}")
            else:
                print(f"   âŒ HTTP Error: {response.status_code}")
                print(f"   Response: {response.text}")
                
        except requests.exceptions.RequestException as e:
            print(f"   âŒ Request Error: {e}")
        except Exception as e:
            print(f"   âŒ Unexpected Error: {e}")
    
    print("\nğŸ‰ Benchmark tests completed!")

if __name__ == "__main__":
    test_benchmark() 